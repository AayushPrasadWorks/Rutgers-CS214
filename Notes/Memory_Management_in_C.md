# Memory Management in C # 

## Introduction ##

When a program is loaded into memory, it is organized into three areas of memory, called segments:
* The text segment
* The stack segment
* The heap segment

The text segment
* aka code segment.
* is where the compiled code of the program itself resides.
* This is the machine language representation of the program steps to be carried out, including all functions making up the program, both user and system defined.

In general, an executable program generated by a compiler (like gcc) will have the following organization in memory on a typical architecture (like MIPS):



where:
* Code segment / text segment: Code segment contains the code executable or code binary.
* Data Segment: Sub-divided into two parts:
  * Initialized data segment: All the global, static, and constant data are stored in the data segment.
  * Uninitialized data segment: All the uninitialized data are stored in BSS.
* Heap: When program(s) allocate memory at runtime using calloc and malloc functions, then memory gets allocated in the heap. When some more memory needs to be allocated using calloc and malloc functions, the heap grows upward as shown in the above diagram.
* Stack: Stack is used to store local variables and is used for passing arguments to the functions along with the return address of the instruction which is to be executed after the function call is over. When a new stack frame needs to be added (as a result of a newly called function), the stack grows downward.

The stack and the heap are traditionally located at opposite ends of the process' virtual address space. 

The stack grows automatically when accessed, up to a size set by the kernel (which can be adjusted with setrlimit(RLIMIT_STACK, …)). 

The heap grows when the memory allocator invokes the brk() or sbrk() system call, mapping more pages of physical memory into the process' virtual address space.

Implementation of both the stack and heap is usually down to the runtime / OS.

## Stack ##

Stack: In computing architectures, stacks are regions of memory where data is added or removed in a last-in-first-out manner.

In most modern computer systems, each thread has a reserved region of memory referred to as its stack.

When a function executes, it may add some of its state data to the top of the stack. 

When the function exits, it is responsible for removing that data from the stack.

At minimum, a thread's stack is used to store the location of function calls in order to allow return statements to return to the correct location, but programmers may further choose to explicitly use the stack.

If a region of memory lies on the thread's stack, that memory is said to have been allocated on the stack.

Salient features of the stack:
* Because a stack follows a LIFO manner for adding/removing data, stack allocation is very simple and typically faster than heap-based memory allocation.
* Memory on the stack is automatically and very efficiently reclaimed whenever the function exits, which is very convenient for the programmer if the data is no longer required.
* However, if the data needs to be preserved or kept in some form, then it must be copied from the stack before the function exits.
* Thus, stack-based allocation is best for temporary data or data which is no longer required after the creating function exits.

### Call Stack ###

A call stack is composed of stack frames (aka activation records).

These are machine-dependent data structures containing subroutine state information. 

Each stack frame corrosponds to a call to a subroutine which has not terminated with a return.

### Additional Information About the Stack ###

Noteworthy:
* The OS allocates the stack for each system-level thread when the thread is created. Typically, the OS is called by the language runtime to allocate the heap for the application.
* The stack is attached to a thread, so when the thread exits, the stack is reclaimed. The heap is typically allocated at application startup by the runtime, and is reclaimed when the application (technically, the process) exits.
* The size of the stack is set when a thread is created.
* The stack is faster because the access pattern makes it trivial to allocate memory from it, while the heap has much more complex bookkeeping involved in an allocation or a free. Also, each byte in the stack tends to be reused very frequently, which means it tends to be mapped to the processor's cache, making it very fast.
* Stored in computer's RAM [like the heap].
* Variables created on the stack will go out of scope and automatically deallocate.
* Much faster to allocate in comparison to variables on the heap.
* Implementation - actual stack data structure.
* Used for storing local data, returning addresses, and passing parameters.
* Stack overflow: when too much of the stack is used [mostly from infinite / too much recursion, or very large allocations].
* Data created on the stack can be used without pointers.
* Use stack if you know exactly how much data you need to allocate before compile time, and make sure it is not too large.
* The stack usually has a maximum size that is already determined when the program starts.

### Stack Overflow ###

Stack-based memory errors - bad bad bad! So bad!

When using heap-based memory, if you overshoot the bounds of the allocated block, it can still trigger a segmentation fault.
**Exception:** If the memory block is incidentally contiguous with another block that was previously allocated.

Variables created on the stack are always contiguous with each other. Writing out of bounds can change the value of another variable.

If your program has stopped obeying the laws of logic, it's probably buffer overflow.  

__Some Ways to Kill the Stack__ 
* Blow the stack by simply using more memory than is available for this thread.  
* The other common error to be careful with is __buffer overflow__, i.e., when we write past the end of some variable, overwriting vital information.  

## Heap ##

* The heap contains a linked list of used and free blocks. 
* New allocations on the heap [by __new__ or __malloc()__] are satisfied by creating a suitable block from one of the free blocks. 
* This requires updating the list of blocks on the heap. 
* This meta information about the blocks on the heap is also stored on the heap, often in a small area just in front of every block. 
* The size of the heap is set on application startup, but can grow [expand] as and when space is required [the allocator requests more space from the OS]. 
* Stored in computer RAM, just like the stack. 
* Variables on the heap must be destroyed manually and must never fall out of scope. The said data is freed using __delete, delete[], or free()__. 
* In comparison to variables on the stack, the heap is slower to allocate. 
* Used on demand to allocate a block of data for use by the program. 
* Can have fragmentation when there are a lot of allocations and deallocations. 
* Can have allocation failures if too big of a buffer is requested to be allocated. 
* Use the heap when you don't know exactly how much data you will need at runtime, or if you need to allocate a lot of data. 
* The heap is responsible for memory leaks. 

### Memory Leaks ### 

A __memory leak__, in computer science [in such a context, aka a leakage], occurs when a computer program consumes memory, but is unable to release it back to the OS. 

A memory leak has symptoms similar to a number of other problems and can generally only be diagnosed by a programmer with access to the program source code; however, many people refer to any unwanted increase in memory usage as a memory leak, though this is not strictly accurate.  

A memory leak can diminish the performance of the computer by reducing the amount of available memory. 

Eventually, in the worst case, too much of the available memory may become allocated, and all or part of the system or device stops working correctly, the application fails, or the system slows down unacceptably due to thrashing.  

Memory leaks may not be serious or even detectable by normal means. In modern operating systems, normal memory used by an application is released when the application terminates. This means that a memory leak in a program that only runs for a short time may not be noticed and is rarely serious.  

Typically, a memory leak occurs because dynamically allocated memory has become unreachable. The prevalence of memory leak bugs has led to the development of a number of debugging tools to detect unreachable memory.  

”Conservative” garbage collection capabilities can be added to any programming language that lacks it as a built-in feature, and libraries for doing this are available for C and C++ programs. A conservative collector finds and reclaims most, but not all,
unreachable memory.  


